{"index":{"version":"0.5.12","fields":[{"name":"title","boost":10},{"name":"keywords","boost":15},{"name":"body","boost":1}],"ref":"url","documentStore":{"store":{"./":["experience.","includ","introduct","iwiki","person","tip","wich","wiki"],"implementation_scheme/":["implement","scheme"],"implementation_scheme/mixed_precision_training_implementation_scheme.html":["implement","mix","precis","scheme","train"],"tech_tools/":["blog","tech","tool"],"tech_tools/git/":["git","tip","tool","us"],"tech_tools/git/gitbook_on_github-page.html":["\"./_book\"","\"gener","\"setting\"","\"the","\"updat","#","./","./*","./_book.","./master_barnch/_book","1.","2.","3.","4.","`gh","`git","`master_barnch`","abov","add","alreadi","automat","b","back","boart","branch","branch,","branch.","branch:","build","built","by:","call","checkout","clone","clone`,","code","codes,","codes:","commit","congrates!","current","dependencies,","directli","docs\"","don't","done,","e.g.,","everyth","file","files.","first","follow","gener","gh","git","gitbook","gitbook'","github","github,","github:","go","init","instal","instruction,","is,","iwiki.","locat","m","master","master_barnch","method","move","mv","name.","need","need,","notic","now","origin","page","pages.","pages`","path","path,","push","r","readme.md","repres","respositori","respository\"","respository'","rf","rm","root","run","save","serv","sourc","state","static","summary.md","then,","time","updates\"","url","us","visit","way,","websit","you."],"paper_reading/":["paper","read"],"paper_reading/model_compression/":["compress","model"],"paper_reading/model_compression/quantization/":["quantiz"],"paper_reading/model_compression/quantization/mixed_precision_training.html":["\"autom","\"compressed\"","\"mix","(default","(henc","0.001).","1.","2)","2,","2.","2.1.","2.1.1.","2.1.2.","2000","absolut","adjust","algorithms,","approach,","author","automat","backoff","begin","both","call","case","check","choos","comput","concretely,","constant","data","decreas","distribut","dure","dynam","each","easi","end","ensur","estim","event","extens","factor","factor\"","factor\".","factor,","factor.","first","float16","float16,","focu","furthermore,","gradient","gradients.","hand,","happen","happens,","here","https://arxiv.org/abs/1710.03740","https://devblogs.nvidia.com/apex","https://github.com/nvidia/apex","https://nvidia.github.io/openseq2seq/html/mix","implement","implementation.","increas","industri","inspect","instance,","inter","introduc","introduct","iter","iteration.","keep","knowledg","larg","last,","less","log","lognorm","loss","lower","maximum","mean","means,","mention","mentioned,","mix","model","more","name),","next","normal","now","number","on","one.","openseq2seq","optim","overflow","overflow,","paper","paramet","period","possibl","precis","precision.html#","presenc","probabl","put","pytorch","rang","rare","read","realli","recip","reference:","repres","respectively).","rule","run","s.t.","scale","scale.","scaling.","select","set","shift","skip","static","statistics,","such","summari","support","system","tech","them.","time,","tip","togeth","train","training\"","training.","training/","two","type,","underflow","underli","understand","understand,","update.","us","valu","varianc","whenev"]},"length":10},"tokenStore":{"root":{"0":{"docs":{},".":{"0":{"0":{"1":{"docs":{},")":{"docs":{},".":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}},"docs":{}},"docs":{}},"docs":{}}},"1":{"docs":{},".":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333},"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}},"2":{"0":{"0":{"0":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}},"docs":{}},"docs":{}},"docs":{},".":{"1":{"docs":{},".":{"1":{"docs":{},".":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}},"2":{"docs":{},".":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}},"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}},"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333},"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}},")":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}},",":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}},"3":{"docs":{},".":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}},"4":{"docs":{},".":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}},"docs":{},"e":{"docs":{},"x":{"docs":{},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{},"i":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},".":{"docs":{"./":{"ref":"./","tf":0.14285714285714285}}}}}}}}}}},"t":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.011406844106463879}}}}}}},".":{"docs":{},"g":{"docs":{},".":{"docs":{},",":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},"y":{"docs":{},"t":{"docs":{},"h":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}},"n":{"docs":{},"t":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0076045627376425855}}}},"s":{"docs":{},"i":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.011406844106463879}}}}},"n":{"docs":{},"d":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}},"s":{"docs":{},"u":{"docs":{},"r":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}},"s":{"docs":{},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}},"i":{"docs":{},"n":{"docs":{},"c":{"docs":{},"l":{"docs":{},"u":{"docs":{},"d":{"docs":{"./":{"ref":"./","tf":0.14285714285714285}}}}},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"s":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0076045627376425855}}}}}}},"t":{"docs":{},"r":{"docs":{},"o":{"docs":{},"d":{"docs":{},"u":{"docs":{},"c":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}},"t":{"docs":{"./":{"ref":"./","tf":10},"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}}},"e":{"docs":{},"r":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0076045627376425855}}}}},"i":{"docs":{},"t":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"l":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},",":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}},"r":{"docs":{},"u":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},",":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}}}}}}},"p":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}},"d":{"docs":{},"u":{"docs":{},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"i":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}}}},"w":{"docs":{},"i":{"docs":{},"k":{"docs":{},"i":{"docs":{"./":{"ref":"./","tf":0.14285714285714285}},".":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}}},"m":{"docs":{},"p":{"docs":{},"l":{"docs":{},"e":{"docs":{},"m":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"implementation_scheme/":{"ref":"implementation_scheme/","tf":5.5},"implementation_scheme/mixed_precision_training_implementation_scheme.html":{"ref":"implementation_scheme/mixed_precision_training_implementation_scheme.html","tf":2.2},"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},".":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}}}}}}}}}}},"s":{"docs":{},",":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.019011406844106463}},"a":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},".":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0076045627376425855}}}}}}}}}}}},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{},"s":{"docs":{},"o":{"docs":{},"n":{"docs":{"./":{"ref":"./","tf":0.14285714285714285}}}}},"i":{"docs":{},"o":{"docs":{},"d":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}},"r":{"docs":{},"e":{"docs":{},"c":{"docs":{},"i":{"docs":{},"s":{"docs":{"implementation_scheme/mixed_precision_training_implementation_scheme.html":{"ref":"implementation_scheme/mixed_precision_training_implementation_scheme.html","tf":2.2},"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":3.3523447401774393}},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{},".":{"docs":{},"h":{"docs":{},"t":{"docs":{},"m":{"docs":{},"l":{"docs":{},"#":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}}}}}}}}},"s":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}},"o":{"docs":{},"b":{"docs":{},"a":{"docs":{},"b":{"docs":{},"l":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}}},"a":{"docs":{},"g":{"docs":{},"e":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":3.3749999999999996}},"s":{"docs":{},".":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}},"`":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}},"t":{"docs":{},"h":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}},",":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}},"p":{"docs":{},"e":{"docs":{},"r":{"docs":{"paper_reading/":{"ref":"paper_reading/","tf":5.5},"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.015209125475285171}}}}},"r":{"docs":{},"a":{"docs":{},"m":{"docs":{},"e":{"docs":{},"t":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.019011406844106463}}}}}}}},"u":{"docs":{},"s":{"docs":{},"h":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.020833333333333332}}}},"t":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}},"o":{"docs":{},"s":{"docs":{},"s":{"docs":{},"i":{"docs":{},"b":{"docs":{},"l":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}}},"y":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"c":{"docs":{},"h":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}}}},"t":{"docs":{},"i":{"docs":{},"p":{"docs":{"./":{"ref":"./","tf":0.14285714285714285},"tech_tools/git/":{"ref":"tech_tools/git/","tf":0.3333333333333333},"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}},"m":{"docs":{},"e":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}},",":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}},"r":{"docs":{},"a":{"docs":{},"i":{"docs":{},"n":{"docs":{"implementation_scheme/mixed_precision_training_implementation_scheme.html":{"ref":"implementation_scheme/mixed_precision_training_implementation_scheme.html","tf":2.2},"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":3.3371356147021545}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"\"":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}},".":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}},"/":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}}}}},"e":{"docs":{},"c":{"docs":{},"h":{"docs":{"tech_tools/":{"ref":"tech_tools/","tf":5.5},"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}},"o":{"docs":{},"o":{"docs":{},"l":{"docs":{"tech_tools/":{"ref":"tech_tools/","tf":5},"tech_tools/git/":{"ref":"tech_tools/git/","tf":0.3333333333333333}}}},"g":{"docs":{},"e":{"docs":{},"t":{"docs":{},"h":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}},"h":{"docs":{},"e":{"docs":{},"n":{"docs":{},",":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}},"m":{"docs":{},".":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}},"w":{"docs":{},"o":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.011406844106463879}}}},"y":{"docs":{},"p":{"docs":{},"e":{"docs":{},",":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}},"w":{"docs":{},"i":{"docs":{},"c":{"docs":{},"h":{"docs":{"./":{"ref":"./","tf":0.14285714285714285}}}},"k":{"docs":{},"i":{"docs":{"./":{"ref":"./","tf":0.14285714285714285}}}}},"a":{"docs":{},"y":{"docs":{},",":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}},"e":{"docs":{},"b":{"docs":{},"s":{"docs":{},"i":{"docs":{},"t":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.020833333333333332}}}}}}},"h":{"docs":{},"e":{"docs":{},"n":{"docs":{},"e":{"docs":{},"v":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}}},"s":{"docs":{},"c":{"docs":{},"h":{"docs":{},"e":{"docs":{},"m":{"docs":{},"e":{"docs":{"implementation_scheme/":{"ref":"implementation_scheme/","tf":5.5},"implementation_scheme/mixed_precision_training_implementation_scheme.html":{"ref":"implementation_scheme/mixed_precision_training_implementation_scheme.html","tf":2.2}}}}}},"a":{"docs":{},"l":{"docs":{},"e":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.07224334600760456}},".":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},".":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0076045627376425855}}}}}}}}},"a":{"docs":{},"v":{"docs":{},"e":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}},"e":{"docs":{},"r":{"docs":{},"v":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}},"l":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}},"t":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}},"o":{"docs":{},"u":{"docs":{},"r":{"docs":{},"c":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}},"t":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}},"i":{"docs":{},"c":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.020833333333333332},"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}},"s":{"docs":{},"t":{"docs":{},"i":{"docs":{},"c":{"docs":{},"s":{"docs":{},",":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}}}}}}},"u":{"docs":{},"m":{"docs":{},"m":{"docs":{},"a":{"docs":{},"r":{"docs":{},"y":{"docs":{},".":{"docs":{},"m":{"docs":{},"d":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}},"i":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}},"c":{"docs":{},"h":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}},"p":{"docs":{},"p":{"docs":{},"o":{"docs":{},"r":{"docs":{},"t":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}}},".":{"docs":{},"t":{"docs":{},".":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}},"h":{"docs":{},"i":{"docs":{},"f":{"docs":{},"t":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}},"k":{"docs":{},"i":{"docs":{},"p":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0076045627376425855}}}}},"y":{"docs":{},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"m":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}}},"m":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.010416666666666666}},"i":{"docs":{},"x":{"docs":{"implementation_scheme/mixed_precision_training_implementation_scheme.html":{"ref":"implementation_scheme/mixed_precision_training_implementation_scheme.html","tf":2.2},"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":3.344740177439797}}}},"a":{"docs":{},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.03125}},"_":{"docs":{},"b":{"docs":{},"a":{"docs":{},"r":{"docs":{},"n":{"docs":{},"c":{"docs":{},"h":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}}}}}}}}},"x":{"docs":{},"i":{"docs":{},"m":{"docs":{},"u":{"docs":{},"m":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.011406844106463879}}}}}}}},"e":{"docs":{},"t":{"docs":{},"h":{"docs":{},"o":{"docs":{},"d":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}},"a":{"docs":{},"n":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0076045627376425855}},"s":{"docs":{},",":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"o":{"docs":{},"n":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}},"e":{"docs":{},"d":{"docs":{},",":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}}}}}},"o":{"docs":{},"v":{"docs":{},"e":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}},"d":{"docs":{},"e":{"docs":{},"l":{"docs":{"paper_reading/model_compression/":{"ref":"paper_reading/model_compression/","tf":5.5},"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}},"r":{"docs":{},"e":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}},"v":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}},"b":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.010416666666666666}},"l":{"docs":{},"o":{"docs":{},"g":{"docs":{"tech_tools/":{"ref":"tech_tools/","tf":0.5}}}}},"a":{"docs":{},"c":{"docs":{},"k":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}},"o":{"docs":{},"f":{"docs":{},"f":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.011406844106463879}}}}}}}},"o":{"docs":{},"a":{"docs":{},"r":{"docs":{},"t":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}},"t":{"docs":{},"h":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}},"r":{"docs":{},"a":{"docs":{},"n":{"docs":{},"c":{"docs":{},"h":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.020833333333333332}},",":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.015625}}},".":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.010416666666666666}}},":":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}}}},"u":{"docs":{},"i":{"docs":{},"l":{"docs":{},"d":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.03125}}},"t":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}},"y":{"docs":{},":":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}},"e":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{"tech_tools/git/":{"ref":"tech_tools/git/","tf":10},"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.052083333333333336}},"b":{"docs":{},"o":{"docs":{},"o":{"docs":{},"k":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":3.3697916666666665}},"'":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}}},"h":{"docs":{},"u":{"docs":{},"b":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":3.3541666666666665}},",":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}},":":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}}}},"e":{"docs":{},"n":{"docs":{},"e":{"docs":{},"r":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}},"h":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.03125}}},"o":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.010416666666666666}}},"r":{"docs":{},"a":{"docs":{},"d":{"docs":{},"i":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.015209125475285171}},"s":{"docs":{},".":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}}}}}}},"u":{"docs":{},"s":{"docs":{"tech_tools/git/":{"ref":"tech_tools/git/","tf":0.3333333333333333},"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.010416666666666666},"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.022813688212927757}}},"p":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},"\"":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}},".":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0076045627376425855}}}}}}}},"r":{"docs":{},"l":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}},"n":{"docs":{},"d":{"docs":{},"e":{"docs":{},"r":{"docs":{},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"w":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}},"l":{"docs":{},"i":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"d":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}},",":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}}}}}}}},"\"":{"docs":{},".":{"docs":{},"/":{"docs":{},"_":{"docs":{},"b":{"docs":{},"o":{"docs":{},"o":{"docs":{},"k":{"docs":{},"\"":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}}}}}},"g":{"docs":{},"e":{"docs":{},"n":{"docs":{},"e":{"docs":{},"r":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}}},"s":{"docs":{},"e":{"docs":{},"t":{"docs":{},"t":{"docs":{},"i":{"docs":{},"n":{"docs":{},"g":{"docs":{},"\"":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}}}}}},"t":{"docs":{},"h":{"docs":{},"e":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}},"u":{"docs":{},"p":{"docs":{},"d":{"docs":{},"a":{"docs":{},"t":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}}},"a":{"docs":{},"u":{"docs":{},"t":{"docs":{},"o":{"docs":{},"m":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0076045627376425855}}}}}}},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{},"e":{"docs":{},"d":{"docs":{},"\"":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}}}}}}}},"m":{"docs":{},"i":{"docs":{},"x":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}},"#":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.015625}}},".":{"docs":{},"/":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}},"*":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.010416666666666666}}},"_":{"docs":{},"b":{"docs":{},"o":{"docs":{},"o":{"docs":{},"k":{"docs":{},".":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}}}},"m":{"docs":{},"a":{"docs":{},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"b":{"docs":{},"a":{"docs":{},"r":{"docs":{},"n":{"docs":{},"c":{"docs":{},"h":{"docs":{},"/":{"docs":{},"_":{"docs":{},"b":{"docs":{},"o":{"docs":{},"o":{"docs":{},"k":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}}}}}}}}}}}}}}}}}}},"`":{"docs":{},"g":{"docs":{},"h":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}},"i":{"docs":{},"t":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}},"m":{"docs":{},"a":{"docs":{},"s":{"docs":{},"t":{"docs":{},"e":{"docs":{},"r":{"docs":{},"_":{"docs":{},"b":{"docs":{},"a":{"docs":{},"r":{"docs":{},"n":{"docs":{},"c":{"docs":{},"h":{"docs":{},"`":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}}}}}}}}}}}}},"a":{"docs":{},"b":{"docs":{},"o":{"docs":{},"v":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}},"s":{"docs":{},"o":{"docs":{},"l":{"docs":{},"u":{"docs":{},"t":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}}},"d":{"docs":{},"d":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.010416666666666666}}},"j":{"docs":{},"u":{"docs":{},"s":{"docs":{},"t":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}},"l":{"docs":{},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{},"i":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}}},"g":{"docs":{},"o":{"docs":{},"r":{"docs":{},"i":{"docs":{},"t":{"docs":{},"h":{"docs":{},"m":{"docs":{},"s":{"docs":{},",":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}}}}}}},"u":{"docs":{},"t":{"docs":{},"o":{"docs":{},"m":{"docs":{},"a":{"docs":{},"t":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333},"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0076045627376425855}}}}}},"h":{"docs":{},"o":{"docs":{},"r":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}},"p":{"docs":{},"p":{"docs":{},"r":{"docs":{},"o":{"docs":{},"a":{"docs":{},"c":{"docs":{},"h":{"docs":{},",":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}}}}}},"c":{"docs":{},"a":{"docs":{},"l":{"docs":{},"l":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333},"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}},"s":{"docs":{},"e":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}},"h":{"docs":{},"e":{"docs":{},"c":{"docs":{},"k":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}},"o":{"docs":{},"u":{"docs":{},"t":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.015625}}}}}}}},"o":{"docs":{},"o":{"docs":{},"s":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}},"l":{"docs":{},"o":{"docs":{},"n":{"docs":{},"e":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}},"`":{"docs":{},",":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}}}},"o":{"docs":{},"d":{"docs":{},"e":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}},"s":{"docs":{},",":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}},":":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}},"m":{"docs":{},"m":{"docs":{},"i":{"docs":{},"t":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.010416666666666666}}}}},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{"paper_reading/model_compression/":{"ref":"paper_reading/model_compression/","tf":5.5}}}}}},"u":{"docs":{},"t":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}},"n":{"docs":{},"g":{"docs":{},"r":{"docs":{},"a":{"docs":{},"t":{"docs":{},"e":{"docs":{},"s":{"docs":{},"!":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}}}}},"c":{"docs":{},"r":{"docs":{},"e":{"docs":{},"t":{"docs":{},"e":{"docs":{},"l":{"docs":{},"y":{"docs":{},",":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}}}}},"s":{"docs":{},"t":{"docs":{},"a":{"docs":{},"n":{"docs":{},"t":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.011406844106463879}}}}}}}}},"u":{"docs":{},"r":{"docs":{},"r":{"docs":{},"e":{"docs":{},"n":{"docs":{},"t":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}}}}},"d":{"docs":{},"e":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"d":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"i":{"docs":{},"e":{"docs":{},"s":{"docs":{},",":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}}}}}}}}},"c":{"docs":{},"r":{"docs":{},"e":{"docs":{},"a":{"docs":{},"s":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0076045627376425855}}}}}}}},"i":{"docs":{},"r":{"docs":{},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{},"l":{"docs":{},"i":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}}}},"s":{"docs":{},"t":{"docs":{},"r":{"docs":{},"i":{"docs":{},"b":{"docs":{},"u":{"docs":{},"t":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}}}}},"o":{"docs":{},"c":{"docs":{},"s":{"docs":{},"\"":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}},"n":{"docs":{},"'":{"docs":{},"t":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}},"e":{"docs":{},",":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}},"a":{"docs":{},"t":{"docs":{},"a":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0076045627376425855}}}}},"u":{"docs":{},"r":{"docs":{},"e":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}},"y":{"docs":{},"n":{"docs":{},"a":{"docs":{},"m":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.011406844106463879}}}}}}},"f":{"docs":{},"i":{"docs":{},"l":{"docs":{},"e":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.026041666666666668}},"s":{"docs":{},".":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}},"r":{"docs":{},"s":{"docs":{},"t":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.010416666666666666},"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}},"o":{"docs":{},"l":{"docs":{},"l":{"docs":{},"o":{"docs":{},"w":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.020833333333333332}}}}}},"c":{"docs":{},"u":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}},"a":{"docs":{},"c":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0076045627376425855}},"\"":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}},".":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}},",":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0076045627376425855}}},".":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0076045627376425855}}}}}}}},"l":{"docs":{},"o":{"docs":{},"a":{"docs":{},"t":{"1":{"6":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}},",":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}},"docs":{}},"docs":{}}}}},"u":{"docs":{},"r":{"docs":{},"t":{"docs":{},"h":{"docs":{},"e":{"docs":{},"r":{"docs":{},"m":{"docs":{},"o":{"docs":{},"r":{"docs":{},"e":{"docs":{},",":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}}}}}}}}},"l":{"docs":{},"o":{"docs":{},"c":{"docs":{},"a":{"docs":{},"t":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.015625}}}}},"g":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}},"n":{"docs":{},"o":{"docs":{},"r":{"docs":{},"m":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.011406844106463879}}}}}}},"s":{"docs":{},"s":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.06463878326996197}}}},"w":{"docs":{},"e":{"docs":{},"r":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}},"a":{"docs":{},"r":{"docs":{},"g":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.011406844106463879}}}},"s":{"docs":{},"t":{"docs":{},",":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}},"e":{"docs":{},"s":{"docs":{},"s":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}},"n":{"docs":{},"a":{"docs":{},"m":{"docs":{},"e":{"docs":{},".":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}},")":{"docs":{},",":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}},"e":{"docs":{},"e":{"docs":{},"d":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.010416666666666666}},",":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}},"x":{"docs":{},"t":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0076045627376425855}}}}},"o":{"docs":{},"t":{"docs":{},"i":{"docs":{},"c":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}},"w":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.010416666666666666},"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}},"r":{"docs":{},"m":{"docs":{},"a":{"docs":{},"l":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}},"u":{"docs":{},"m":{"docs":{},"b":{"docs":{},"e":{"docs":{},"r":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}}},"o":{"docs":{},"r":{"docs":{},"i":{"docs":{},"g":{"docs":{},"i":{"docs":{},"n":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.010416666666666666}}}}}}},"n":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0076045627376425855}},"e":{"docs":{},".":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"2":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.011406844106463879}}}}}},"docs":{}}}}}},"t":{"docs":{},"i":{"docs":{},"m":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.011406844106463879}}}}}},"v":{"docs":{},"e":{"docs":{},"r":{"docs":{},"f":{"docs":{},"l":{"docs":{},"o":{"docs":{},"w":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.011406844106463879}},",":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.015209125475285171}}}}}}}}}}},"r":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}},"e":{"docs":{},"a":{"docs":{},"d":{"docs":{"paper_reading/":{"ref":"paper_reading/","tf":5.5},"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}},"m":{"docs":{},"e":{"docs":{},".":{"docs":{},"m":{"docs":{},"d":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}}}},"l":{"docs":{},"l":{"docs":{},"i":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}},"p":{"docs":{},"r":{"docs":{},"e":{"docs":{},"s":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333},"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0076045627376425855}}}}}},"s":{"docs":{},"p":{"docs":{},"o":{"docs":{},"s":{"docs":{},"i":{"docs":{},"t":{"docs":{},"o":{"docs":{},"r":{"docs":{},"i":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}},"y":{"docs":{},"\"":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}},"'":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.010416666666666666}}}}}}}}}},"e":{"docs":{},"c":{"docs":{},"t":{"docs":{},"i":{"docs":{},"v":{"docs":{},"e":{"docs":{},"l":{"docs":{},"y":{"docs":{},")":{"docs":{},".":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}}}}}}}}},"c":{"docs":{},"i":{"docs":{},"p":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}},"f":{"docs":{},"e":{"docs":{},"r":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{},"e":{"docs":{},":":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}}}}}},"f":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}},"m":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}},"o":{"docs":{},"o":{"docs":{},"t":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}},"u":{"docs":{},"n":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.015625},"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}},"l":{"docs":{},"e":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}},"a":{"docs":{},"n":{"docs":{},"g":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0076045627376425855}}}},"r":{"docs":{},"e":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}},"v":{"docs":{},"i":{"docs":{},"s":{"docs":{},"i":{"docs":{},"t":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}},"a":{"docs":{},"l":{"docs":{},"u":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0076045627376425855}}}},"r":{"docs":{},"i":{"docs":{},"a":{"docs":{},"n":{"docs":{},"c":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}}}},"y":{"docs":{},"o":{"docs":{},"u":{"docs":{},".":{"docs":{"tech_tools/git/gitbook_on_github-page.html":{"ref":"tech_tools/git/gitbook_on_github-page.html","tf":0.005208333333333333}}}}}},"q":{"docs":{},"u":{"docs":{},"a":{"docs":{},"n":{"docs":{},"t":{"docs":{},"i":{"docs":{},"z":{"docs":{"paper_reading/model_compression/quantization/":{"ref":"paper_reading/model_compression/quantization/","tf":11}}}}}}}}},"(":{"docs":{},"d":{"docs":{},"e":{"docs":{},"f":{"docs":{},"a":{"docs":{},"u":{"docs":{},"l":{"docs":{},"t":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.011406844106463879}}}}}}}}},"h":{"docs":{},"e":{"docs":{},"n":{"docs":{},"c":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}},"h":{"docs":{},"a":{"docs":{},"n":{"docs":{},"d":{"docs":{},",":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}},"p":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}},"s":{"docs":{},",":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}}}},"e":{"docs":{},"r":{"docs":{},"e":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}},"t":{"docs":{},"t":{"docs":{},"p":{"docs":{},"s":{"docs":{},":":{"docs":{},"/":{"docs":{},"/":{"docs":{},"a":{"docs":{},"r":{"docs":{},"x":{"docs":{},"i":{"docs":{},"v":{"docs":{},".":{"docs":{},"o":{"docs":{},"r":{"docs":{},"g":{"docs":{},"/":{"docs":{},"a":{"docs":{},"b":{"docs":{},"s":{"docs":{},"/":{"1":{"7":{"1":{"0":{"docs":{},".":{"0":{"3":{"7":{"4":{"0":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}},"docs":{}},"docs":{}},"docs":{}},"docs":{}}}}}}}}}}}}}}},"d":{"docs":{},"e":{"docs":{},"v":{"docs":{},"b":{"docs":{},"l":{"docs":{},"o":{"docs":{},"g":{"docs":{},"s":{"docs":{},".":{"docs":{},"n":{"docs":{},"v":{"docs":{},"i":{"docs":{},"d":{"docs":{},"i":{"docs":{},"a":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"/":{"docs":{},"a":{"docs":{},"p":{"docs":{},"e":{"docs":{},"x":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}}}}}}}}}}}}}}}}}}}}},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{},"h":{"docs":{},"u":{"docs":{},"b":{"docs":{},".":{"docs":{},"c":{"docs":{},"o":{"docs":{},"m":{"docs":{},"/":{"docs":{},"n":{"docs":{},"v":{"docs":{},"i":{"docs":{},"d":{"docs":{},"i":{"docs":{},"a":{"docs":{},"/":{"docs":{},"a":{"docs":{},"p":{"docs":{},"e":{"docs":{},"x":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}}}}}}}}}}}}}}}}}}},"n":{"docs":{},"v":{"docs":{},"i":{"docs":{},"d":{"docs":{},"i":{"docs":{},"a":{"docs":{},".":{"docs":{},"g":{"docs":{},"i":{"docs":{},"t":{"docs":{},"h":{"docs":{},"u":{"docs":{},"b":{"docs":{},".":{"docs":{},"i":{"docs":{},"o":{"docs":{},"/":{"docs":{},"o":{"docs":{},"p":{"docs":{},"e":{"docs":{},"n":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"2":{"docs":{},"s":{"docs":{},"e":{"docs":{},"q":{"docs":{},"/":{"docs":{},"h":{"docs":{},"t":{"docs":{},"m":{"docs":{},"l":{"docs":{},"/":{"docs":{},"m":{"docs":{},"i":{"docs":{},"x":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}}}}}}}}}},"docs":{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"k":{"docs":{},"e":{"docs":{},"e":{"docs":{},"p":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}},"n":{"docs":{},"o":{"docs":{},"w":{"docs":{},"l":{"docs":{},"e":{"docs":{},"d":{"docs":{},"g":{"docs":{"paper_reading/model_compression/quantization/mixed_precision_training.html":{"ref":"paper_reading/model_compression/quantization/mixed_precision_training.html","tf":0.0038022813688212928}}}}}}}}}}},"length":292},"corpusTokens":["\"./_book\"","\"autom","\"compressed\"","\"gener","\"mix","\"setting\"","\"the","\"updat","#","(default","(henc","./","./*","./_book.","./master_barnch/_book","0.001).","1.","2)","2,","2.","2.1.","2.1.1.","2.1.2.","2000","3.","4.","`gh","`git","`master_barnch`","abov","absolut","add","adjust","algorithms,","alreadi","approach,","author","automat","b","back","backoff","begin","blog","boart","both","branch","branch,","branch.","branch:","build","built","by:","call","case","check","checkout","choos","clone","clone`,","code","codes,","codes:","commit","compress","comput","concretely,","congrates!","constant","current","data","decreas","dependencies,","directli","distribut","docs\"","don't","done,","dure","dynam","e.g.,","each","easi","end","ensur","estim","event","everyth","experience.","extens","factor","factor\"","factor\".","factor,","factor.","file","files.","first","float16","float16,","focu","follow","furthermore,","gener","gh","git","gitbook","gitbook'","github","github,","github:","go","gradient","gradients.","hand,","happen","happens,","here","https://arxiv.org/abs/1710.03740","https://devblogs.nvidia.com/apex","https://github.com/nvidia/apex","https://nvidia.github.io/openseq2seq/html/mix","implement","implementation.","includ","increas","industri","init","inspect","instal","instance,","instruction,","inter","introduc","introduct","is,","iter","iteration.","iwiki","iwiki.","keep","knowledg","larg","last,","less","locat","log","lognorm","loss","lower","m","master","master_barnch","maximum","mean","means,","mention","mentioned,","method","mix","model","more","move","mv","name),","name.","need","need,","next","normal","notic","now","number","on","one.","openseq2seq","optim","origin","overflow","overflow,","page","pages.","pages`","paper","paramet","path","path,","period","person","possibl","precis","precision.html#","presenc","probabl","push","put","pytorch","quantiz","r","rang","rare","read","readme.md","realli","recip","reference:","repres","respectively).","respositori","respository\"","respository'","rf","rm","root","rule","run","s.t.","save","scale","scale.","scaling.","scheme","select","serv","set","shift","skip","sourc","state","static","statistics,","such","summari","summary.md","support","system","tech","them.","then,","time","time,","tip","togeth","tool","train","training\"","training.","training/","two","type,","underflow","underli","understand","understand,","update.","updates\"","url","us","valu","varianc","visit","way,","websit","whenev","wich","wiki","you."],"pipeline":["stopWordFilter","stemmer"]},"store":{"./":{"url":"./","title":"Introduction","keywords":"","body":"iwiki\nThis is my personal wiki wich include some of tips or experience.\n"},"implementation_scheme/":{"url":"implementation_scheme/","title":"Implementation Scheme","keywords":"","body":"Implementation Scheme\n"},"implementation_scheme/mixed_precision_training_implementation_scheme.html":{"url":"implementation_scheme/mixed_precision_training_implementation_scheme.html","title":"mixed-precision training implementation scheme","keywords":"","body":"mixed-precision training implementation scheme\n"},"tech_tools/":{"url":"tech_tools/","title":"Tech Tools","keywords":"","body":"Tech Blog\n"},"tech_tools/git/":{"url":"tech_tools/git/","title":"Git","keywords":"","body":"tools using tips\n"},"tech_tools/git/gitbook_on_github-page.html":{"url":"tech_tools/git/gitbook_on_github-page.html","title":"Gitbook On Github-page","keywords":"","body":"gitbook on github-page\n1. Building a Respository on Github, e.g., iwiki.\n2. Building a Branch Called gh-pages\nAfter building following branch, github will automatically serves a github-page for you.\ngit checkout -b gh-pages\n3. Building Gitbook Static Website Files\nFirst go back to master branch:\ngit checkout master\nThen, after installing gitbook and its dependencies, build README.md and SUMMARY.md following gitbook \ninstruction, and run following codes to generate static website files which were located at ./_book.\ngitbook init\ngitbook build\nNow we can push all these files to master branch, by the way, the master branch is used for saving your \ngitbook's source files.\ngit add ./*\ngit commit -m \"General updates\"\ngit push origin master\n4. Moving Gitbook Static Website Files To gh-pages Branch\nFirst go to gh-pages branch by:\ngit checkout gh-pages\nNotice this time we don't need -b since we have already built this branch.  \nAfter running above codes, we need the static website files in \"./_book\" located \nat master branch, so the most directly method is running following codes:\n# The current state is, located at the respository's root path, with `gh-pages`\n# branch. After `git clone`, use the `master_barnch` represents the \n# respository's path name.\n\ngit clone \"the respository\"\nmv -r ./master_barnch/_book ./\nrm -rf master_barnch\nNow we get all we need, so push to github:\ngit add ./*\ngit commit -m \"Update docs\"\ngit push original gh-pages\nCongrates! Everything done, you can visit the \"Setting\" boart to get the url \nof your github pages.\n"},"paper_reading/":{"url":"paper_reading/","title":"Paper Reading","keywords":"","body":"Paper Reading\n"},"paper_reading/model_compression/":{"url":"paper_reading/model_compression/","title":"Model Compression","keywords":"","body":"Model Compression\n"},"paper_reading/model_compression/quantization/":{"url":"paper_reading/model_compression/quantization/","title":"Quantization","keywords":"","body":"Quantization\n"},"paper_reading/model_compression/quantization/mixed_precision_training.html":{"url":"paper_reading/model_compression/quantization/mixed_precision_training.html","title":"Mixed Precision Training","keywords":"","body":"Mixed Precision Training\n\nreference:  https://arxiv.org/abs/1710.03740  https://github.com/NVIDIA/apex  https://nvidia.github.io/OpenSeq2Seq/html/mixed-precision.html#  https://devblogs.nvidia.com/apex-pytorch-easy-mixed-precision-training/ \n\n1. Introduction\nThe paper \"Mixed Precision Training\" is easy to read after understanding \nsome underlying computer system knowledge such as data type, so here just \nintroduce some tips and extension of the paper by summary some industrial \nimplementation.  \n2. Extension\n2.1. Loss Scaling\nAs the paper mentioned, loss scaling is really useful when putting the \"compressed\" \nparameters into the range in which lower data precision can represent them. This tech \ncould be used in two approach, one is using static loss scaling factor, other is using \ndynamic loss scaling factor. The first one is easy to understand, now focus on the \ndynamic one.  \nThe paper mentioned \"automating loss-scaling factor\" at last, the author means, for \ninstance, if some gradients or parameters happened overflow, which means these number \nis to large to represented by float16, so we should decrease loss-scaling factor, on \nthe other hand, if underflow happens, in this case we should increase loss-scaling \nfactor.  \nOpenSeq2Seq did more on \"automating loss-scaling factor\". OpenSeq2Seq implements \nan extension to the mixed precision recipe that we call automatic loss scaling. \nThe optimizer inspects the parameter gradients at each iteration and uses their \nvalues to select the loss scale for the next iteration.  Concretely, OpenSeq2Seq \nhas support for two automatic loss scaling algorithms, Backoff and LogNormal scaling.  \n2.1.1. Backoff Scaling\nBackoff scaling begins with a large loss scale and checks for overflow in the \nparameter gradients at the end of each iteration. Whenever there is an overflow, \nthe loss scale decreases by a constant factor (default is 2) and the optimizer will \nskip the update. Furthermore, if there has been no overflow for a period of time, \nthe loss scale increases by a constant factor (defaults are 2000 iterations and 2, \nrespectively). These two rules together ensure both that the loss scale is as large \nas possible and also that it can adjust to shifting dynamic range during training.\n2.1.2. LogNormal Scaling\nLogNormal scaling uses gradient statistics, rather than the presence of overflow, \nto set the loss scale. It keeps a running estimate of the mean and variance of \nthe inter-iteration maximum absolute value of the parameter gradients. It models \nthe inter-iteration maximum as log-normally distributed (hence the name), and then \nchooses the loss scale for the next iteration s.t. the probability of the maximum \noverflowing float16 is less than some constant (default is 0.001). In the rare \nevent of an overflow, the optimizer skips the update.\n"}}}